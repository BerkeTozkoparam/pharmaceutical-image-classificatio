# -*- coding: utf-8 -*-
"""Transfer Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-0jGtGjdyYzmuowQCJepPw7-8HXHKfii
"""

import os
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

SEED = 42
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 10

DATA_DIR = "/content/pharma_dataset"  # change if needed

np.random.seed(SEED)
tf.random.set_seed(SEED)

data_dir = Path(DATA_DIR)
img_exts = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}

file_paths = []
labels = []

for class_dir in sorted([p for p in data_dir.iterdir() if p.is_dir()]):
    for fp in class_dir.rglob("*"):
        if fp.suffix.lower() in img_exts:
            file_paths.append(str(fp))
            labels.append(class_dir.name)

image_df = pd.DataFrame({"File_path": file_paths, "labes": labels})

print("Total images:", len(image_df))
print("Columns:", image_df.columns.tolist())
print(image_df.head())

label_counts = image_df["labes"].value_counts()
print("\nClass distribution (top 10):")
print(label_counts.head(10))

n_show = 25
if len(image_df) >= n_show:
    random_index = np.random.randint(0, len(image_df), n_show)
    fig, axes = plt.subplots(5, 5, figsize=(11, 11))
    for i, ax in enumerate(axes.flat):
        img_path = image_df["File_path"].iloc[random_index[i]]
        label = image_df["labes"].iloc[random_index[i]]
        ax.imshow(plt.imread(img_path))
        ax.set_title(str(label))
        ax.axis("off")
    plt.tight_layout()
    plt.show()

train_df, val_df = train_test_split(
    image_df,
    test_size=0.2,
    stratify=image_df["labes"],
    random_state=SEED
)

train_generator = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

val_generator = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col="File_path",
    y_col="labes",
    target_size=IMG_SIZE,
    color_mode="rgb",
    class_mode="categorical",
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=SEED
)

val_images = val_generator.flow_from_dataframe(
    dataframe=val_df,
    x_col="File_path",
    y_col="labes",
    target_size=IMG_SIZE,
    color_mode="rgb",
    class_mode="categorical",
    batch_size=BATCH_SIZE,
    shuffle=False
)

NUM_CLASSES = len(train_images.class_indices)
print("\nNumber of classes:", NUM_CLASSES)
print("Class indices:", train_images.class_indices)

pretrained_model = MobileNetV2(
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),
    include_top=False,
    weights="imagenet",
    pooling="avg"
)
pretrained_model.trainable = False

inputs = pretrained_model.input
x = pretrained_model.output
x = layers.Dense(128, activation="relu")(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(NUM_CLASSES, activation="softmax")(x)

model = keras.Model(inputs, outputs)

model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

checkpoint_callback = ModelCheckpoint(
    filepath="pharma_model.weights.h5",
    save_weights_only=True,
    monitor="val_accuracy",
    mode="max",
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(
    monitor="val_accuracy",
    mode="max",
    patience=5,
    restore_best_weights=True,
    verbose=1
)

history = model.fit(
    train_images,
    validation_data=val_images,
    epochs=EPOCHS,
    callbacks=[checkpoint_callback, early_stopping]
)

plt.figure(figsize=(8, 4))
plt.plot(history.history.get("accuracy", []), label="Training Accuracy")
plt.plot(history.history.get("val_accuracy", []), label="Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(8, 4))
plt.plot(history.history.get("loss", []), label="Training Loss")
plt.plot(history.history.get("val_loss", []), label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.show()

val_images.reset()
pred_probs = model.predict(val_images, verbose=1)
y_pred = np.argmax(pred_probs, axis=1)
y_true = val_images.classes

idx_to_class = {v: k for k, v in train_images.class_indices.items()}
target_names = [idx_to_class[i] for i in range(NUM_CLASSES)]

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=target_names))

cm = confusion_matrix(y_true, y_pred)
print("\nConfusion Matrix shape:", cm.shape)

# Fine Tunning
pretrained_model.trainable = True

for layer in pretrained_model.layers[:-40]:
    layer.trainable = False

model.compile(
    optimizer=Adam(1e-5),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

history_ft = model.fit(
    train_images,
    validation_data=val_images,
    epochs=8,
    callbacks=[checkpoint_callback, early_stopping]
)

# Testing
best_weights_path = "pharma_model.weights.h5"
model.load_weights(best_weights_path)

val_loss, val_acc = model.evaluate(val_images, verbose=1)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_acc:.4f}")

import numpy as np
from sklearn.metrics import classification_report

val_images.reset()
pred_probs = model.predict(val_images, verbose=1)
y_pred = np.argmax(pred_probs, axis=1)
y_true = val_images.classes

idx_to_class = {v: k for k, v in train_images.class_indices.items()}
target_names = [idx_to_class[i] for i in range(len(idx_to_class))]

print(classification_report(y_true, y_pred, target_names=target_names, digits=4))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10, 8))
plt.imshow(cm)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.colorbar()
plt.show()

#Prediction
def predict_top5(image_path, top_k=5):
    img = Image.open(image_path).convert("RGB").resize((224, 224))
    x = np.array(img).astype(np.float32)
    x = preprocess_input(x)
    x = np.expand_dims(x, axis=0)

    probs = model.predict(x, verbose=0)[0]
    top_idx = np.argsort(probs)[::-1][:top_k]

    results = [(idx_to_class[i], float(probs[i])) for i in top_idx]
    return results

for cls, p in predict_top5(image_path):
    print(f"{cls}: {p:.4f}")

!pip install gradio

import os
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from google.colab import files
from sklearn.metrics import roc_curve, auc, confusion_matrix
from sklearn.preprocessing import label_binarize
from itertools import cycle

# --- SETTINGS AND DIRECTORY CREATION ---
save_dir = "project_graphs"
os.makedirs(save_dir, exist_ok=True)
sns.set(style="whitegrid", context="notebook")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 12

print(f"Generating graphs and saving to '{save_dir}' directory...")

# 1. SAVE CLASS DISTRIBUTION
plt.figure(figsize=(12, 6))
class_counts = image_df['labes'].value_counts()
sns.barplot(x=class_counts.index, y=class_counts.values, palette="viridis")
plt.title("Class Distribution (Number of Images per Class)")
plt.xlabel("Classes")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(f"{save_dir}/1_class_distribution.png", dpi=300)
plt.close()

# 2. SAVE CONFUSION MATRIX
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(10, 8))
sns.heatmap(cm_normalized, annot=True, fmt=".2f", cmap="Blues",
            xticklabels=target_names, yticklabels=target_names)
plt.title("Normalized Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig(f"{save_dir}/2_confusion_matrix.png", dpi=300)
plt.close()

# 3. SAVE CLASS-WISE ACCURACY
class_accuracy = cm.diagonal() / cm.sum(axis=1)
plt.figure(figsize=(12, 6))
sns.barplot(x=target_names, y=class_accuracy, palette="rocket")
plt.axhline(y=np.mean(class_accuracy), color='r', linestyle='--', label=f'Mean Accuracy: {np.mean(class_accuracy):.2f}')
plt.title("Class-wise Accuracy Rates")
plt.xlabel("Classes")
plt.ylabel("Accuracy")
plt.ylim(0, 1.1)
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.savefig(f"{save_dir}/3_class_accuracy.png", dpi=300)
plt.close()

# 4. SAVE ROC CURVES
y_test_bin = label_binarize(y_true, classes=range(NUM_CLASSES))
n_classes = y_test_bin.shape[1]
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(10, 8))
colors = cycle(['blue', 'red', 'green', 'orange', 'purple', 'cyan'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'{target_names[i]} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-class ROC Curve')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.savefig(f"{save_dir}/4_roc_curve.png", dpi=300)
plt.close()

# 5. SAVE TRAINING HISTORY (If history exists)
if 'history' in globals():
    acc = history.history.get('accuracy', [])
    val_acc = history.history.get('val_accuracy', [])
    loss = history.history.get('loss', [])
    val_loss = history.history.get('val_loss', [])
    epochs_range = range(1, len(acc) + 1)

    plt.figure(figsize=(14, 5))

    # Accuracy Subplot
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy', linestyle='--')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss Subplot
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss', linestyle='--')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.savefig(f"{save_dir}/5_training_history.png", dpi=300)
    plt.close()

# --- ZIP AND DOWNLOAD ---
print("Zipping files...")
shutil.make_archive("project_graphs_english", 'zip', save_dir)

print("Starting download...")
files.download("project_graphs_english.zip")